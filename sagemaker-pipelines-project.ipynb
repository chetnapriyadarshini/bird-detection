{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrating Jobs, Model Registration, and Continuous Deployment with Amazon SageMaker\n",
    "\n",
    "Amazon SageMaker offers Machine Learning application developers and Machine Learning operations engineers the ability to orchestrate SageMaker jobs and author reproducible Machine Learning pipelines, deploy custom-build models for inference in real-time with low latency or offline inferences with Batch Transform, and track lineage of artifacts. You can institute sound operational practices in deploying and monitoring production workflows, deployment of model artifacts, and track artifact lineage through a simple interface, adhering to safety and best-practice paradigmsfor Machine Learning application development.\n",
    "\n",
    "The SageMaker Pipelines service supports a SageMaker Machine Learning Pipeline Domain Specific Language (DSL), which is a declarative Json specification. This DSL defines a Directed Acyclic Graph (DAG) of pipeline parameters and SageMaker job steps. The SageMaker Python Software Developer Kit (SDK) streamlines the generation of the pipeline DSL using constructs that are already familiar to engineers and scientists alike.\n",
    "\n",
    "The SageMaker Model Registry is where trained models are stored, versioned, and managed. Data Scientists and Machine Learning Engineers can compare model versions, approve models for deployment, and deploy models from different AWS accounts, all from a single Model Registry. SageMaker enables customers to follow the best practices with ML Ops and getting started right. Customers are able to standup a full ML Ops end-to-end system with a single API call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layout of the SageMaker ModelBuild Project Template\n",
    "\n",
    "The template provides a starting point for bringing your SageMaker Pipeline development to production.\n",
    "\n",
    "```\n",
    "|-- codebuild-buildspec.yml\n",
    "|-- CONTRIBUTING.md\n",
    "|-- pipelines\n",
    "|   |-- birddetect\n",
    "|   |   |-- evaluateion.py\n",
    "|   |   |-- __init__.py\n",
    "|   |   |-- pipeline.py\n",
    "|   |   `-- preprocess.py\n",
    "|   |-- get_pipeline_definition.py\n",
    "|   |-- __init__.py\n",
    "|   |-- run_pipeline.py\n",
    "|   |-- _utils.py\n",
    "|   `-- __version__.py\n",
    "|-- README.md\n",
    "|-- sagemaker-pipelines-project.ipynb\n",
    "|-- setup.cfg\n",
    "|-- setup.py\n",
    "|-- tests\n",
    "|   `-- test_pipelines.py\n",
    "`-- tox.ini\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A description of some of the artifacts is provided below:\n",
    "<br/><br/>\n",
    "Your codebuild execution instructions:\n",
    "```\n",
    "|-- codebuild-buildspec.yml\n",
    "```\n",
    "<br/><br/>\n",
    "Your pipeline artifacts, which includes a pipeline module defining the required `get_pipeline` method that returns an instance of a SageMaker pipeline, a preprocessing script that is used in feature engineering, and a model evaluation script to measure the Mean Squared Error of the model that's trained by the pipeline:\n",
    "\n",
    "```\n",
    "|-- pipelines\n",
    "|   |-- abalone\n",
    "|   |   |-- evaluate.py\n",
    "|   |   |-- __init__.py\n",
    "|   |   |-- pipeline.py\n",
    "|   |   `-- preprocess.py\n",
    "\n",
    "```\n",
    "\n",
    "For additional subfolders with code and/or artifacts needed by pipeline, they need to be packaged correctly by the `setup.py` file. For example, to package a `pipelines/source` folder,\n",
    "\n",
    "* Include a `__init__.py` file within the `source` folder.\n",
    "* Add it to the `setup.py` file's `package_data` like so:\n",
    "\n",
    "```\n",
    "...\n",
    "    packages=setuptools.find_packages(),\n",
    "    include_package_data=True,\n",
    "    package_data={\"pipelines.my_pipeline.src\": [\"*.txt\"]},\n",
    "    python_requires=\">=3.6\",\n",
    "    install_requires=required_packages,\n",
    "    extras_require=extras,\n",
    "...\n",
    "```\n",
    "\n",
    "<br/><br/>\n",
    "Utility modules for getting pipeline definition jsons and running pipelines:\n",
    "\n",
    "```\n",
    "|-- pipelines\n",
    "|   |-- get_pipeline_definition.py\n",
    "|   |-- __init__.py\n",
    "|   |-- run_pipeline.py\n",
    "|   |-- _utils.py\n",
    "|   `-- __version__.py\n",
    "```\n",
    "<br/><br/>\n",
    "Python package artifacts:\n",
    "```\n",
    "|-- setup.cfg\n",
    "|-- setup.py\n",
    "```\n",
    "<br/><br/>\n",
    "A stubbed testing module for testing your pipeline as you develop:\n",
    "```\n",
    "|-- tests\n",
    "|   `-- test_pipelines.py\n",
    "```\n",
    "<br/><br/>\n",
    "The `tox` testing framework configuration:\n",
    "```\n",
    "`-- tox.ini\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A SageMaker Pipeline\n",
    "\n",
    "The pipeline that we create follows a typical Machine Learning Application pattern of pre-processing, training, evaluation, and conditional model registration and publication, if the quality of the model is sufficient.\n",
    "\n",
    "![A typical ML Application pipeline](img/pipeline-full.png)\n",
    "\n",
    "### Getting some constants\n",
    "\n",
    "We get some constants from the local execution environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "default_bucket = sagemaker_session.default_bucket() # or use your own custom bucket name we will use default bucket\n",
    "region = sagemaker_session.boto_region_name\n",
    "account = sagemaker_session.account_id()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "base_job_prefix = 'End2End-Bird-detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-09-22 12:59:23--  https://s3.amazonaws.com/fast-ai-imageclas/CUB_200_2011.tgz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.41.112\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.41.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1150585339 (1.1G) [application/x-tar]\n",
      "Saving to: ‘CUB_200_2011.tgz’\n",
      "\n",
      "CUB_200_2011.tgz    100%[===================>]   1.07G  44.7MB/s    in 20s     \n",
      "\n",
      "2022-09-22 12:59:45 (55.9 MB/s) - ‘CUB_200_2011.tgz’ saved [1150585339/1150585339]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://s3.amazonaws.com/fast-ai-imageclas/CUB_200_2011.tgz'\n",
    "!tar xopf CUB_200_2011.tgz\n",
    "!rm CUB_200_2011.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!apt-get update\n",
    "!apt-get install ffmpeg libsm6 libxext6  -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "\n",
    "img_array = []\n",
    "image_dir = 'CUB_200_2011/images'\n",
    "\n",
    "subset_data = [\"013.Bobolink\", \"017.Cardinal\", \n",
    "               \"035.Purple_Finch\", \"036.Northern_Flicker\",\n",
    "              \"047.American_Goldfinch\",\"068.Ruby_throated_Hummingbird\",\n",
    "               \"073.Blue_Jay\",\"087.Mallard\"]\n",
    "\n",
    "# create an array of available image files\n",
    "for sub_dir in os.listdir(image_dir):\n",
    "    if sub_dir in subset_data:\n",
    "\n",
    "        for filename in os.listdir(f'{image_dir}/{sub_dir}'):\n",
    "            img_array.append(f'{image_dir}/{sub_dir}/{filename}')\n",
    "            \n",
    "# all the images should be the same size, so grab teh image size from first image\n",
    "img = cv2.imread(img_array[0])\n",
    "height, width, layers = img.shape\n",
    "size = (width,height)\n",
    "\n",
    "output_path = '../2_deployment/bird.mp4'\n",
    "out = cv2.VideoWriter(output_path,cv2.VideoWriter_fourcc(*'MP4V'), 1, size)\n",
    "\n",
    "#random sample images and append as frames into the video\n",
    "for i in range(200):\n",
    "    rand_index = random.randint(0,len(img_array)-1)\n",
    "    img = cv2.imread(img_array[rand_index])\n",
    "    out.write(img)\n",
    "out.release()\n",
    "\n",
    "print(f'video generated at {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the images to our local bucket.\n",
    "\n",
    "label_map = dict()\n",
    "for i in range(len(subset_data)):\n",
    "    label = subset_data[i].split('.')[-1]\n",
    "    label_map[label] = i\n",
    "        \n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "input_manifest_name = 'input.manifest'\n",
    "output_manifest_name = 'output.manifest'\n",
    "\n",
    "# remove if file already exist\n",
    "if os.path.exists(input_manifest_name):\n",
    "    os.remove(input_manifest_name)\n",
    "    \n",
    "if os.path.exists(output_manifest_name):\n",
    "    os.remove(output_manifest_name)\n",
    "\n",
    "f = open(input_manifest_name, 'a')\n",
    "g = open(output_manifest_name, 'a')\n",
    "\n",
    "json_body = {'labels':[]}\n",
    "\n",
    "print('Processing......\\n')\n",
    "\n",
    "for raw_label in os.listdir(image_dir):\n",
    "    \n",
    "    if raw_label in subset_data:\n",
    "    \n",
    "        label_name = raw_label.split('.')[-1]\n",
    "\n",
    "        print(label_name, label_map[label_name])\n",
    "        json_body['labels'].append({\"label\": label_name})\n",
    "\n",
    "        for filename in os.listdir(f'{image_dir}/{raw_label}'):\n",
    "            if '.jpg' in filename:\n",
    "                key = f\"{base_job_prefix}/unlabeled/images/{filename}\"\n",
    "                s3.upload_file(f'{image_dir}/{raw_label}/{filename}', default_bucket, key)\n",
    "\n",
    "                img_path = f\"s3://{default_bucket}/{key}\"\n",
    "                f.write('{\"source-ref\": \"' + img_path + '\"}\\n')\n",
    "\n",
    "                #build output manifest, if you don't want to go through the label        \n",
    "                output_manifest = dict()\n",
    "\n",
    "                output_manifest['source-ref'] = img_path\n",
    "                output_manifest['label'] = label_map[label_name]\n",
    "                label_metadata = dict()\n",
    "                label_metadata['class-name'] = label_name\n",
    "                # these are just placeholders to mimic an actual manifest file\n",
    "                label_metadata['job-name'] = \"labeling-job/bird-image-classification-1634678978\"\n",
    "                label_metadata['type'] = \"groundtruth/image-classification\"\n",
    "                label_metadata['human-annotated'] = \"yes\"\n",
    "                label_metadata['creation-date'] = str(datetime.datetime.now().isoformat(timespec='microseconds'))\n",
    "\n",
    "                output_manifest['label-metadata'] = label_metadata\n",
    "\n",
    "                g.write(f\"{json.dumps(output_manifest)}\\n\")\n",
    "        \n",
    "        \n",
    "f.close()\n",
    "g.close()\n",
    "        \n",
    "        \n",
    "input_manifest_key = f\"{base_job_prefix}/unlabeled/manifest/{input_manifest_name}\"\n",
    "s3.upload_file(input_manifest_name, default_bucket, input_manifest_key)\n",
    "        \n",
    "s3_input_manifest = f\"s3://{default_bucket}/{input_manifest_key}\"\n",
    "\n",
    "print(\"\\nInput manifest file location:\")\n",
    "print(s3_input_manifest)\n",
    "\n",
    "output_manifest_key = f\"{base_job_prefix}/pipeline/manifest/{output_manifest_name}\"\n",
    "s3.upload_file(output_manifest_name, default_bucket, output_manifest_key)\n",
    "        \n",
    "s3_output_manifest = f\"s3://{default_bucket}/{output_manifest_key}\"\n",
    "\n",
    "print(\"\\nSynthetic output manifest file location: \")\n",
    "print(s3_output_manifest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./CUB_200_2011\n",
    "!rm -f attributes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(json_body)\n",
    "\n",
    "class_file_name = \"class_labels.json\"\n",
    "with open(class_file_name, \"w\") as f:\n",
    "    json.dump(json_body, f)\n",
    "\n",
    "classes_key = f\"{base_job_prefix}/unlabeled/classes/{class_file_name}\"\n",
    "s3.upload_file(class_file_name, default_bucket, classes_key)\n",
    "\n",
    "s3_classes = f\"s3://{default_bucket}/{classes_key}\"\n",
    "\n",
    "s3_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_template(test_template=False, save_fname=\"instructions.template\"):\n",
    "    template = r\"\"\"<script src=\"https://assets.crowd.aws/crowd-html-elements.js\"></script>\n",
    "        <crowd-form>\n",
    "          <crowd-image-classifier\n",
    "            name=\"crowd-image-classifier\"\n",
    "            src=\"{{ task.input.taskObject | grant_read_access }}\"\n",
    "            header=\"please classify\"\n",
    "            categories=\"{{ task.input.labels | to_json | escape }}\"\n",
    "          >\n",
    "            <full-instructions header=\"Image classification instructions\">\n",
    "              <ol><li><strong>Read</strong> the task carefully and inspect the image.</li>\n",
    "              <li><strong>Read</strong> the options and review the examples provided to understand more about the labels.</li>\n",
    "              <li><strong>Choose</strong> the appropriate label that best suits the image.</li></ol>\n",
    "            </full-instructions>\n",
    "            <short-instructions>\n",
    "              <p>Dear Annotator, please tell me whether what you can see in the image. Thank you!</p>\n",
    "            </short-instructions>\n",
    "          </crowd-image-classifier>\n",
    "        </crowd-form>\"\"\"\n",
    "\n",
    "    with open(save_fname, \"w\") as f:\n",
    "        f.write(template)\n",
    "    if test_template is False:\n",
    "        print(template)\n",
    "\n",
    "template_name = \"instructions.template\"\n",
    "# make_template(test_template=True, save_fname=\"instructions.html\")\n",
    "\n",
    "make_template(test_template=False, save_fname=template_name)\n",
    "templates_key = f\"{base_job_prefix}/unlabeled/templates/{template_name}\"\n",
    "s3.upload_file(template_name, default_bucket, templates_key)\n",
    "\n",
    "s3_templates = f\"s3://{default_bucket}/{templates_key}\"\n",
    "print(f\"S3 url: {s3_templates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify ARNs for resources needed to run an image classification job.\n",
    "ac_arn_map = {\n",
    "    \"us-west-2\": \"081040173940\",\n",
    "    \"us-east-1\": \"432418664414\",\n",
    "    \"us-east-2\": \"266458841044\",\n",
    "    \"eu-west-1\": \"568282634449\",\n",
    "    \"ap-northeast-1\": \"477331159723\",\n",
    "}\n",
    "\n",
    "prehuman_arn = \"arn:aws:lambda:{}:{}:function:PRE-ImageMultiClass\".format(\n",
    "    region, ac_arn_map[region]\n",
    ")\n",
    "acs_arn = \"arn:aws:lambda:{}:{}:function:ACS-ImageMultiClass\".format(region, ac_arn_map[region])\n",
    "\n",
    "labeling_algorithm_specification_arn = \"arn:aws:sagemaker:{}:027400017018:labeling-job-algorithm-specification/image-classification\".format(\n",
    "    region\n",
    ")\n",
    "\n",
    "#Update this code block if you want to use your own private workforce.\n",
    "PRIVATE_WORKFORCE = False\n",
    "\n",
    "public_workteam_arn = \"arn:aws:sagemaker:{}:394669845002:workteam/public-crowd/default\".format(region)\n",
    "\n",
    "# private_workteam_arn = \"<REPLACE WITH YOUR OWN PRIVATE TEAM ARN>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = \"bird-image-classification-\" + str(int(time.time())).split('.')[0]\n",
    "\n",
    "# define human task configuration\n",
    "human_task_config = {\n",
    "    \"AnnotationConsolidationConfig\": {\n",
    "        \"AnnotationConsolidationLambdaArn\": acs_arn,\n",
    "    },\n",
    "    \"PreHumanTaskLambdaArn\": prehuman_arn,\n",
    "    \"MaxConcurrentTaskCount\": 200,  # 200 images will be sent at a time to the workteam.\n",
    "    \"NumberOfHumanWorkersPerDataObject\": 3,  # 3 separate workers will be required to label each image.\n",
    "    \"TaskAvailabilityLifetimeInSeconds\": 21600,  # Your worteam has 6 hours to complete all pending tasks.\n",
    "    \"TaskDescription\": 'Carefully inspect the image and classify it by selecting one label from the categories provided.',\n",
    "    \"TaskKeywords\": [\"image\", \"classification\", \"birds\"],\n",
    "    \"TaskTimeLimitInSeconds\": 300,  # Each image must be labeled within 5 minutes.\n",
    "    \"TaskTitle\": 'What bird is this',\n",
    "    \"UiConfig\": {\n",
    "        \"UiTemplateS3Uri\": s3_templates,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Using public or private workforce.  Public workforce require price info\n",
    "if not PRIVATE_WORKFORCE:\n",
    "    human_task_config[\"PublicWorkforceTaskPrice\"] = {\n",
    "        \"AmountInUsd\": {\n",
    "            \"Dollars\": 0,\n",
    "            \"Cents\": 1,\n",
    "            \"TenthFractionsOfACent\": 2,\n",
    "        }\n",
    "    }\n",
    "    human_task_config[\"WorkteamArn\"] = public_workteam_arn\n",
    "else:\n",
    "    human_task_config[\"WorkteamArn\"] = private_workteam_arn\n",
    "    \n",
    "ground_truth_request = {\n",
    "    \"InputConfig\": {\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"ManifestS3Uri\": s3_input_manifest\n",
    "            }\n",
    "        },\n",
    "        \"DataAttributes\": {\n",
    "            \"ContentClassifiers\": [\"FreeOfPersonallyIdentifiableInformation\", \"FreeOfAdultContent\"]\n",
    "        },\n",
    "    },\n",
    "    \"OutputConfig\": {\n",
    "        \"S3OutputPath\": f's3://{default_bucket}/{base_job_prefix}/labeled',\n",
    "    },\n",
    "    \"HumanTaskConfig\": human_task_config,\n",
    "    \"LabelingJobName\": job_name,\n",
    "    \"RoleArn\": role,\n",
    "    \"LabelAttributeName\": \"category\",\n",
    "    \"LabelCategoryConfigS3Uri\": s3_classes,\n",
    "}\n",
    "\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "sagemaker_client.create_labeling_job(**ground_truth_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_name = 'bird-image-classification-1647438119'\n",
    "# sagemaker_client = boto3.client(\"sagemaker\")\n",
    "sagemaker_client.describe_labeling_job(LabelingJobName=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the output manifest's annotations.\n",
    "output_manifest = f\"s3://{default_bucket}/{base_job_prefix}/labeled/{job_name}/manifests/intermediate/1/output.manifest\"\n",
    "\n",
    "!aws s3 cp {output_manifest} 'output.manifest'\n",
    "\n",
    "with open(\"output.manifest\", \"r\") as f:\n",
    "    output = [json.loads(line.strip()) for line in f.readlines()]\n",
    "\n",
    "# Create data arrays.\n",
    "img_uris = [None] * len(output)\n",
    "confidences = np.zeros(len(output))\n",
    "groundtruth_labels = [None] * len(output)\n",
    "human = np.zeros(len(output))\n",
    "\n",
    "# Find the job name the manifest corresponds to.\n",
    "keys = list(output[0].keys())\n",
    "metakey = keys[np.where([(\"-metadata\" in k) for k in keys])[0][0]]\n",
    "jobname = metakey[:-9]\n",
    "\n",
    "# Extract the data.\n",
    "for datum_id, datum in enumerate(output):\n",
    "    img_uris[datum_id] = datum[\"source-ref\"]\n",
    "    groundtruth_labels[datum_id] = str(datum[metakey][\"class-name\"])\n",
    "    #confidences[datum_id] = datum[metakey][\"confidence\"]\n",
    "    human[datum_id] = int(datum[metakey][\"human-annotated\"] == \"yes\")\n",
    "groundtruth_labels = np.array(groundtruth_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of annotations in each class.\n",
    "n_classes = len(set(groundtruth_labels))\n",
    "sorted_clnames, class_sizes = zip(*Counter(groundtruth_labels).most_common(n_classes))\n",
    "\n",
    "# Find ids of human-annotated images.\n",
    "human_sizes = [human[groundtruth_labels == clname].sum() for clname in sorted_clnames]\n",
    "class_sizes = np.array(class_sizes)\n",
    "human_sizes = np.array(human_sizes)\n",
    "\n",
    "plt.figure(figsize=(9, 3), facecolor=\"white\", dpi=100)\n",
    "plt.title(\"Annotation histogram\")\n",
    "plt.bar(range(n_classes), human_sizes, color=\"gray\", hatch=\"/\", edgecolor=\"k\", label=\"human\")\n",
    "plt.bar(\n",
    "    range(n_classes),\n",
    "    class_sizes - human_sizes,\n",
    "    bottom=human_sizes,\n",
    "    color=\"gray\",\n",
    "    edgecolor=\"k\",\n",
    "    label=\"machine\",\n",
    ")\n",
    "plt.xticks(range(n_classes), sorted_clnames, rotation=90)\n",
    "plt.ylabel(\"Annotation Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image location\n",
    "s3_input_data = f\"s3://{default_bucket}/{base_job_prefix}/unlabeled/images\"\n",
    "# labelled manifest location\n",
    "s3_input_manifest = f\"s3://{default_bucket}/{base_job_prefix}/pipeline/manifest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize './pipelines/birddetect/preprocess.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize './pipelines/birddetect/code/train_debugger.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize './pipelines/birddetect/evaluation.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize './pipelines/birddetect/pipeline_tuning.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pipeline.pipeline import get_pipeline\n",
    "from pipelines.birddetect.pipeline_tuning import get_pipeline\n",
    "\n",
    "model_package_group_name = f\"{base_job_prefix}ModelGroup\"  # Model name in model registry\n",
    "pipeline_name = f\"{base_job_prefix}Pipeline\"  # SageMaker Pipeline name\n",
    "\n",
    "pipeline = get_pipeline(\n",
    "    region=region,\n",
    "    role=role,\n",
    "    default_bucket=default_bucket,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    pipeline_name=pipeline_name,\n",
    "    base_job_prefix=base_job_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        InputDataUrl=s3_input_data, # loaction of the raw data\n",
    "        InputManifestUrl=s3_input_manifest,\n",
    "        ProcessingInstanceCount=1,\n",
    "#         ProcessingInstanceType=\"ml.m5.xlarge\",\n",
    "#         TrainingInstanceCount=1,\n",
    "#         TrainingInstanceType=\"ml.p3.2xlarge\",\n",
    "        ModelApprovalStatus=\"PendingManualApproval\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT REQUIRED - Please enter the S3 URI of the model artifact\n",
    "# eg: s3://sagemaker-us-east-1-xxxxxxxx/BIRD-Sagemaker-Deployment/BIRD-Sagemaker-Deployment-2022-07-27-03-33-54-592/output/model.tar.gz\n",
    "bird_model_path = 's3://sagemaker-us-east-1-729987989507/a8hovs5dbbn8-End2End-3xrsS1pWuZ-001-7d7393a3/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker.serverless as Serverless\n",
    "\n",
    "serverless_inf_config = Serverless.ServerlessInferenceConfig(memory_size_in_mb=3072, max_concurrency=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!Endpoint [tensorflow-inference-2022-09-22-10-29-12-372] deployed\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "TF_FRAMEWORK_VERSION = '2.4.1'\n",
    "model = TensorFlowModel(\n",
    "    model_data=bird_model_path, \n",
    "    role=role,\n",
    "    framework_version=TF_FRAMEWORK_VERSION)\n",
    "\n",
    "\n",
    "predictor = model.deploy(serverless_inference_config=serverless_inf_config)\n",
    "tf_endpoint_name = str(predictor.endpoint_name)\n",
    "print(f\"Endpoint [{predictor.endpoint_name}] deployed\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import Predictor\n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "#Update the below variable with your endpoint name from previous cell output\n",
    "#tf_endpoint_name='<SAGEMAKER DEPLOYED ENDPOINT NAME>'\n",
    "tf_endpoint_name = 'tensorflow-inference-2022-09-22-10-29-12-372'\n",
    "\n",
    "serializer = IdentitySerializer(content_type=\"application/x-image\")\n",
    "deserializer = JSONDeserializer(accept='application/json')\n",
    "\n",
    "predictor = Predictor(endpoint_name=tf_endpoint_name,serializer = serializer,deserializer = deserializer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv_utils\n",
    "\n",
    "classes_file = f\"s3://default_bucket/{base_job_prefix}/full/data/classes.txt\"\n",
    "classes = [13, 17, 35, 36, 47, 68, 73, 87]\n",
    "\n",
    "possible_classes= cv_utils.get_classes_as_list(classes_file,classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['013.Bobolink',\n",
       " '017.Cardinal',\n",
       " '035.Purple_Finch',\n",
       " '036.Northern_Flicker',\n",
       " '047.American_Goldfinch',\n",
       " '068.Ruby_throated_Hummingbird',\n",
       " '073.Blue_Jay',\n",
       " '087.Mallard']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_classes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./inference-test-data/Bobolink_0001_9261.jpg']\n"
     ]
    }
   ],
   "source": [
    "import cv_utils\n",
    "sample_images = cv_utils.get_n_random_images(default_bucket,prefix=f'{base_job_prefix}/outputs/test',n=1)\n",
    "\n",
    "local_paths = cv_utils.download_images_locally(default_bucket,sample_images)\n",
    "print(local_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 013.Bobolink, Confidence :1.00 \n",
      " ./inference-test-data/Bobolink_0001_9261.jpg\n"
     ]
    }
   ],
   "source": [
    "for inputfile in local_paths:\n",
    "    cv_utils.predict_bird_from_file(inputfile,predictor,possible_classes)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_model_package_group(sm_client, package_group_name):\n",
    "    try:\n",
    "        model_versions = sm_client.list_model_packages(ModelPackageGroupName=package_group_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"{} \\n\".format(e))\n",
    "        return\n",
    "\n",
    "    for model_version in model_versions[\"ModelPackageSummaryList\"]:\n",
    "        try:\n",
    "            sm_client.delete_model_package(ModelPackageName=model_version[\"ModelPackageArn\"])\n",
    "        except Exception as e:\n",
    "            print(\"{} \\n\".format(e))\n",
    "        time.sleep(0.5)  # Ensure requests aren't throttled\n",
    "\n",
    "    try:\n",
    "        sm_client.delete_model_package_group(ModelPackageGroupName=package_group_name)\n",
    "        print(\"{} model package group deleted\".format(package_group_name))\n",
    "    except Exception as e:\n",
    "        print(\"{} \\n\".format(e))\n",
    "    return\n",
    "\n",
    "\n",
    "def delete_sagemaker_pipeline(sm_client, pipeline_name):\n",
    "    try:\n",
    "        sm_client.delete_pipeline(\n",
    "            PipelineName=pipeline_name,\n",
    "        )\n",
    "        print(\"{} pipeline deleted\".format(pipeline_name))\n",
    "    except Exception as e:\n",
    "        print(\"{} \\n\".format(e))\n",
    "        return\n",
    "    \n",
    "def delete_sagemaker_project(sm_client, project_name):\n",
    "    try:\n",
    "        sm_client.delete_project(\n",
    "        \n",
    "            ProjectName=project_name,\n",
    "        )\n",
    "        print(\"{} project deleted\".format(project_name))\n",
    "    except Exception as e:\n",
    "        print(\"{} \\n\".format(e))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
